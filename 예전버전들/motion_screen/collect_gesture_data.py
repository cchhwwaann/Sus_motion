import cv2
import mediapipe as mp
import numpy as np
import pandas as pd

mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)

cap = cv2.VideoCapture(0)
gesture_label = None  # í˜„ì¬ ë ˆì´ë¸”
data = []

print("ğŸ“¢ ì›í•˜ëŠ” ì†ë™ì‘ì„ ì·¨í•œ í›„, í‚¤ë³´ë“œì—ì„œ ìˆ«ìë¥¼ ëˆŒëŸ¬ ë ˆì´ë¸”ì„ ì§€ì •í•˜ì„¸ìš”.")
print("ğŸ”¢ ì˜ˆ: 0(í´ë¦­), 1(ë³¼ë¥¨ ì—…), 2(ë³¼ë¥¨ ë‹¤ìš´) ...")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(rgb_frame)

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            
            landmarks = []
            for lm in hand_landmarks.landmark:
                landmarks.append([lm.x, lm.y, lm.z])

            if gesture_label is not None:
                row = [gesture_label] + np.array(landmarks).flatten().tolist()
                data.append(row)

    cv2.imshow('Collect Gesture Data', frame)
    key = cv2.waitKey(1) & 0xFF

    # ìˆ«ìë¥¼ ì…ë ¥í•˜ë©´ í•´ë‹¹ ê°’ì´ ë ˆì´ë¸”ë¡œ ì„¤ì •ë¨
    if ord('0') <= key <= ord('9'):
        gesture_label = int(chr(key))
        print(f"âœ… í˜„ì¬ ë ˆì´ë¸”: {gesture_label}")

    # që¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
    if key == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# ë°ì´í„° ì €ì¥
df = pd.DataFrame(data)
df.to_csv('hand_gestures.csv', index=False, header=False)
print("ğŸ“ ì†ë™ì‘ ë°ì´í„°ê°€ 'hand_gestures.csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
